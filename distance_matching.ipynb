{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Analysis: The Effect of Social Feedback in a Reddit Community\n",
    "In this notebook we demonstrate the use of \"matching\" when using observational data to estimate the effect size of receiving a \"treatment\" vs. not receiving a treatment, i.e. being in the \"control\" group. The vast majority of this notebook has been put together by Tiago Cunha. https://sites.google.com/site/tiagocunha87/\n",
    "\n",
    "In this concrete example we use real data from the Reddit community called \"loseit\", an online forum dedicated to weight loss.\n",
    "https://www.reddit.com/r/loseit/\n",
    "\n",
    "We want to see if the treatment of receiving a \"warm welcome\" on one's first post in this subreddit has an effect on a user's probability to return for a second post in the future. Concretely, we look at the number of upvotes a post receives and define users whose first post on loseit did not receive a single upvote as the control group (see e.g. https://www.reddit.com/r/loseit/comments/o3h7y). Correspondingly, we define users whose first post received at least one upvote as the treatment group (see e.g. https://www.reddit.com/r/loseit/comments/238r4o).\n",
    "\n",
    "The data we are using for this tutorial covers 37,279 users whose first post occurred between August 2010\n",
    "to October 2014. The data was obtained by crawling Reddit using PRAW (http://praw.readthedocs.org), a Python package that allows simple access to Reddit's official API. For more details see the corresponding DigitalHealth'16 publication: Tiago Cunha, Ingmar Weber, Hamed Haddadi, Gisele Pappa: The Effect of Social Feedback in a Weight Loss Subreddit, preprint at http://arxiv.org/abs/1602.07936.\n",
    "\n",
    "\n",
    "The number of upvotes a user receives is clearly affected by their writing style and the subject matter of their first post. A user with a can-do attitude might write more positively and hence be more likely to receive upvotes. If this user then returns for a second post in the future, this might have been due to their attitude and not the feedback received. Similarly, a user who's depressed might write a sad post and not receive any upvotes. If this user then fails to return for a second post in the future it is again unclear if that is because of the lack of support or because of their inherent attitude.\n",
    "\n",
    "To correct for this, we match each treated user with a similar control user. For this analysis we define \"similar\" in terms of LDA (Latent Dirichlet Allocation - a probabilistic topic model). Two users, or rather their first posts in the loseit subreddit, are said to be similar if their LDA topic distributions have a high cosine similarity. To save time, we have pre-computed the LDA topics of each post in our data set using the GibbsLDA++ implementation (http://gibbslda.sourceforge.net/). \n",
    "\n",
    "When doing matching, there are a couple of variants one can try such as:\n",
    "- match either with or without replacement where the control group members can or cannot be reused for several pairings\n",
    "- define a cut-off on how the closest match needs to be in order to be considered \"similar\" at all\n",
    "- use different distance metrics, in particular Mahalanobis Distance (https://en.wikipedia.org/wiki/Mahalanobis_distance) for co-variates that have not been normalized\n",
    "\n",
    "This IPython Notebook allows you to experiment with the first two (replacement or not, and different cut-offs), but the distance is fixed as cosine similarity for efficiency reasons to ensure the script runs fast enough to be interactive.\n",
    "\n",
    "As a general introduction to using matching for causal inference from observational data, we highly recommend Gary King's presentation: https://www.youtube.com/watch?v=rBv39pK1iEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just importing some packages\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import sys\n",
    "from gensim import similarities\n",
    "from random import sample\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We start by defining a bunch of functions. Nothing happening here (yet). Skip further down if you're impatient.\n",
    "## Reads the covariates file, here pre-computed LDA topics for each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the LDA file\n",
    "def get_covariates(featuresFile):\n",
    "\n",
    "    try:\n",
    "        with open(featuresFile) as f:\n",
    "            data = f.read()\n",
    "    except:\n",
    "        print (\"Wrong similarity file\")\n",
    "        sys.exit(0)\n",
    "    data = data.split(\"\\n\")\n",
    "    data.pop(len(data)-1)\n",
    "    count = 0\n",
    "    docs = []\n",
    "    docToPost = {}\n",
    "    postToDoc = {}\n",
    "    count = 0\n",
    "    \n",
    "    for line in data:\n",
    "        x = line.split(\",\")\n",
    "        post = x[len(x)-1]\n",
    "        x.pop(len(x)-1)\n",
    "        docToPost[count] = post\n",
    "        postToDoc[post]  =count\n",
    "        count+=1\n",
    "        docs.append(list(map(float, x)))\n",
    "\n",
    "    size = len(docs)\n",
    "    num_features = len(docs[0])\n",
    "\n",
    "    for j in range(0, size):\n",
    "        for i in range(0,num_features):\n",
    "            docs[j][i] = i, docs[j][i]\n",
    "    return docs, docToPost, num_features, postToDoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reads the number of upvotes received on first posts and if the authors later returned or not for a second post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_information(postsFile):\n",
    "    try:\n",
    "        with open(postsFile) as f:\n",
    "            data = f.read()\n",
    "    except:\n",
    "        print (\"Wrong similarity file\")\n",
    "        sys.exit(0)\n",
    "    data = data.split(\"\\n\")\n",
    "    data.pop(0)\n",
    "    data.pop(len(data)-1)\n",
    "\n",
    "    upvotes = {}\n",
    "    postsReturn = {}\n",
    "    for line in data:\n",
    "        x = line.split(\",\")\n",
    "        upvotes[x[0]] = float(x[1])\n",
    "        postsReturn[x[0]] = x[2]\n",
    "    return upvotes, postsReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This function performs the matching and splits the data into a treatment and (matched) control group\n",
    "It supports different minimal similarity thresholds and supports matching both with and without replacement. A distance of \"None\" means that no matching is performed, which is the baseline case. The only non-trivial distance supported at the moment is \"cosine\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matching(docs, docToPost, upvotes, threshold, replacement, distance = None):\n",
    "\n",
    "    #treament group\n",
    "    treatment = []\n",
    "    treatmentToPost= {}\n",
    "    #control group\n",
    "    control = []\n",
    "    controlToPost = {}\n",
    "    size = len(docs)\n",
    "    countTreatment = 0\n",
    "    countControl = 0\n",
    "    #SPLIT THE DATA INTO TREATMENT (feedback > 0) AND CONTROL (feedback == 0) GROUPS\n",
    "    for x in range(0,size):\n",
    "        if upvotes[docToPost[x]] == 0:\n",
    "            #GET THE CONTROL GROUP\n",
    "            control.append(docs[x])\n",
    "            controlToPost[countControl] = docToPost[x]\n",
    "            countControl+=1\n",
    "        else:\n",
    "            #GET THE TREATMENT GROUP\n",
    "            treatment.append(docs[x])\n",
    "            treatmentToPost[countTreatment] = docToPost[x]\n",
    "            countTreatment+=1\n",
    "\n",
    "    print (\"Treatment group = \"+str(countTreatment)+\" users\")\n",
    "    print (\"Control group = \"+str(countControl)+\" users\")\n",
    "\n",
    "    #Doesnt apply matching\n",
    "    if distance == None:\n",
    "        return treatmentToPost.values(), controlToPost.values()\n",
    "    #matching\n",
    "    else: \n",
    "        similarity = {}\n",
    "        similarity_return = {}\n",
    "\n",
    "        ranking = {}\n",
    "\n",
    "        size = len(control)\n",
    "\n",
    "        matched = {}\n",
    "\n",
    "        countUnmatched = 0\n",
    "\n",
    "        #shuffle the control group to reduce selection bias\n",
    "        lookUpControl = sample(range(0, size), size)\n",
    "        if distance == \"cosine\":\n",
    "            #create an index to speedup the queries with cosine distance\n",
    "            index = similarities.SparseMatrixSimilarity(treatment, num_features=len(treatment[0]))\n",
    "\n",
    "        matchedControl = []\n",
    "        matchedTreament = []\n",
    "        count_pairs = 0\n",
    "        #the matching itself\n",
    "        for x in range(0,size):\n",
    "            #cosine distance\n",
    "            if distance == \"cosine\":\n",
    "                sims =  index[control[lookUpControl[x]]]\n",
    "                closer = sorted(list(enumerate(sims)), key = itemgetter(1), reverse = True)\n",
    "            y = 0\n",
    "            #If false apply matching without replacement\n",
    "            if replacement == False:\n",
    "                #check for users already matched\n",
    "                while treatmentToPost[closer[y][0]] in matched:\n",
    "                    y+=1\n",
    "\n",
    "            #If the similarity is bigger than the threshold, then match the users\n",
    "            if closer[y][1]>=float(threshold):\n",
    "                ranking[controlToPost[lookUpControl[x]]] = closer[y][1]\n",
    "                similarity[controlToPost[lookUpControl[x]]] = treatmentToPost[closer[y][0]],closer[y][1]\n",
    "                matched[treatmentToPost[closer[y][0]]] = 1\n",
    "                similarity_return[count_pairs] = controlToPost[lookUpControl[x]], treatmentToPost[closer[y][0]]\n",
    "                matchedControl.append(controlToPost[lookUpControl[x]])\n",
    "                matchedTreament.append(treatmentToPost[closer[y][0]])\n",
    "                count_pairs+=1\n",
    "            else:\n",
    "                countUnmatched+=1\n",
    "\n",
    "        print (\"Control users left unmatched (due to similarity threshold) = \"+str(countUnmatched))    \n",
    "    \n",
    "        #sort the pairs by similarity\n",
    "        sorted_posts = sorted(ranking.items(), key = itemgetter(1), reverse = True)\n",
    "\n",
    "        #print the top 5 pairs by similarity\n",
    "        count = 0\n",
    "        print (\"\\n\\nTop 5 pairs by similarity\\n\")\n",
    "        for x in sorted_posts:\n",
    "            if count<5:\n",
    "                print (\"Control:\")\n",
    "                print (\"https://www.reddit.com/r/loseit/comments/\"+x[0][3:]+\"\\n\")\n",
    "                print (\"Treatment:\")\n",
    "                print (\"https://www.reddit.com/r/loseit/comments/\"+similarity[x[0]][0][3:]+\"\\n\")\n",
    "                print (\"Cosine similarity = \"+str(similarity[x[0]][1])+\"\\n\\n\")\n",
    "                count+=1\n",
    "        return matchedTreament, matchedControl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given a treatment and control group, this function computes the two \"user returns for second post\" rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rate(treatment, control, returns):\n",
    "\n",
    "    treatmentReturn = 0\n",
    "    controlReturn = 0\n",
    "\n",
    "    both = 0\n",
    "    neither = 0\n",
    "    #number of control users that came back\n",
    "    for user in control:\n",
    "        if returns[user] == \"true\":\n",
    "            controlReturn+=1\n",
    "    #number of treatment users that came back\n",
    "    for user in treatment:\n",
    "        if returns[user] == \"true\":\n",
    "            treatmentReturn+=1\n",
    "\n",
    "    probTreatmentReturn = treatmentReturn/(float(len(treatment)))\n",
    "    probControlReturn = controlReturn/(float(len(control)))\n",
    "    bothReturn = (treatmentReturn+controlReturn)/(float(len(treatment)+len(control)))\n",
    "    neitherReturn = 1-bothReturn\n",
    "    \n",
    "    print (\"Probability of treatment user return = \"+ format(probTreatmentReturn, '.2%'))    \n",
    "    print (\"Probability of control user return = \"+format(probControlReturn, '.2%'))\n",
    "    print (\"Relative increase = \"+format((probTreatmentReturn-probControlReturn)/probControlReturn,'.2%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, the fun begins!\n",
    "## From here onward, things actually get executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ THE COVARIATE FILES (= pre-computed LDA topics for the users' first posts)\n",
    "docs, docToPost, numFeatures, postToDoc = get_covariates(\"featuresFirstPosts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ THE FIRST POSTS INFORMATIONS, NUMBER OF UPVOTES RECEIVED AND IF THE AUTHORS RETURNED OR NOT\n",
    "upvotes, returns = get_posts_information(\"firstPostReturns.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate effect size without matching (baseline)\n",
    "## This just compares the \"returns for second post\" rate for users who (i) don't receive any upvote (= control group), and who (ii) receive at least one upvote (= treatment group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment group = 34939 users\n",
      "Control group = 2340 users\n"
     ]
    }
   ],
   "source": [
    "#Get control and treatment groups\n",
    "#arguments: covariates, postIDs, feedback, threshold, replacement\n",
    "# The missing \"distance\" argument at the end means that no matching is performed\n",
    "treatment, control = distance_matching(docs, docToPost, upvotes, 0.9, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of treatment user return = 30.22%\n",
      "Probability of control user return = 21.58%\n",
      "Relative increase = 40.02%\n"
     ]
    }
   ],
   "source": [
    "#Compute the return rate of control and treatment group\n",
    "#arguments: treatment group, control group, if the authors returned\n",
    "return_rate(treatment, control, returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate effect size with matching\n",
    "## Case 1: Matching without replacement\n",
    "Here users in the treatment group can only be matched to one user in the control group. \n",
    "The argument of \"0.9\" indicates the minimal threshold for cosine similarity to be considered a match.\n",
    "The argument of \"False\" indicates \"without replacement\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment group = 34939 users\n",
      "Control group = 2340 users\n",
      "Control users left unmatched (due to similarity threshold) = 1157\n",
      "\n",
      "\n",
      "Top 5 pairs by similarity\n",
      "\n",
      "Control:\n",
      "https://www.reddit.com/r/loseit/comments/224d1q\n",
      "\n",
      "Treatment:\n",
      "https://www.reddit.com/r/loseit/comments/f5sza\n",
      "\n",
      "Cosine similarity = 0.99488276\n",
      "\n",
      "\n",
      "Control:\n",
      "https://www.reddit.com/r/loseit/comments/2aeljt\n",
      "\n",
      "Treatment:\n",
      "https://www.reddit.com/r/loseit/comments/167pw5\n",
      "\n",
      "Cosine similarity = 0.9870385\n",
      "\n",
      "\n",
      "Control:\n",
      "https://www.reddit.com/r/loseit/comments/1vgr2v\n",
      "\n",
      "Treatment:\n",
      "https://www.reddit.com/r/loseit/comments/2cw67l\n",
      "\n",
      "Cosine similarity = 0.9866215\n",
      "\n",
      "\n",
      "Control:\n",
      "https://www.reddit.com/r/loseit/comments/18k5gx\n",
      "\n",
      "Treatment:\n",
      "https://www.reddit.com/r/loseit/comments/2f6riz\n",
      "\n",
      "Cosine similarity = 0.9860636\n",
      "\n",
      "\n",
      "Control:\n",
      "https://www.reddit.com/r/loseit/comments/lcb4w\n",
      "\n",
      "Treatment:\n",
      "https://www.reddit.com/r/loseit/comments/rda9c\n",
      "\n",
      "Cosine similarity = 0.98387253\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perform the matching and return control and treatment group\n",
    "#arguments: covariates, postIDs, feedback, threshold, replacement, distance\n",
    "treatment, control = distance_matching(docs, docToPost, upvotes, 0.9, False, \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of treatment user return = 28.40%\n",
      "Probability of control user return = 21.30%\n",
      "Relative increase = 33.33%\n"
     ]
    }
   ],
   "source": [
    "#Compute the return rate of control and treatment group\n",
    "#arguments: treatment group, control group, if the authors returned\n",
    "return_rate(treatment, control, returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate effect size with matching\n",
    "## Case 2: Matching with replacement\n",
    "Here users in the treatment group can be matched to several users in the control group. \n",
    "The argument of \"0.9\" indicates the minimal threshold for cosine similarity to be considered a match.\n",
    "The argument of \"True\" indicates \"with replacement\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment group = 34939 users\n",
      "Control group = 2340 users\n",
      "Control users left unmatched (due to similarity threshold) = 1135\n",
      "\n",
      "\n",
      "Top 5 pairs by similarity\n",
      "\n",
      "Control:\n",
      "https://www.reddit.com/r/loseit/comments/224d1q\n",
      "\n",
      "Treatment:\n",
      "https://www.reddit.com/r/loseit/comments/f5sza\n",
      "\n",
      "Cosine similarity = 0.99488276\n",
      "\n",
      "\n",
      "Control:\n",
      "https://www.reddit.com/r/loseit/comments/2aeljt\n",
      "\n",
      "Treatment:\n",
      "https://www.reddit.com/r/loseit/comments/167pw5\n",
      "\n",
      "Cosine similarity = 0.9870385\n",
      "\n",
      "\n",
      "Control:\n",
      "https://www.reddit.com/r/loseit/comments/1vgr2v\n",
      "\n",
      "Treatment:\n",
      "https://www.reddit.com/r/loseit/comments/2cw67l\n",
      "\n",
      "Cosine similarity = 0.9866215\n",
      "\n",
      "\n",
      "Control:\n",
      "https://www.reddit.com/r/loseit/comments/18k5gx\n",
      "\n",
      "Treatment:\n",
      "https://www.reddit.com/r/loseit/comments/2f6riz\n",
      "\n",
      "Cosine similarity = 0.9860636\n",
      "\n",
      "\n",
      "Control:\n",
      "https://www.reddit.com/r/loseit/comments/lcb4w\n",
      "\n",
      "Treatment:\n",
      "https://www.reddit.com/r/loseit/comments/rda9c\n",
      "\n",
      "Cosine similarity = 0.98387253\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perform the matching and return control and treatment group\n",
    "#arguments: covariates, postIDs, feedback, threshold, replacement, distance\n",
    "treatment, control = distance_matching(docs, docToPost, upvotes, 0.9, True, \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of treatment user return = 27.05%\n",
      "Probability of control user return = 21.24%\n",
      "Relative increase = 27.34%\n"
     ]
    }
   ],
   "source": [
    "#Compute the return rate of control and treatment group\n",
    "#arguments: treatment group, control group, if the authors returned\n",
    "return_rate(treatment, control, returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lessons learned\n",
    "You should have seen the estimated effect size shrink when going from the unmatched baseline to the matched sample estimate. This is the standard setting where not controlling for covariates can lead to an overly optimistic effect size.\n",
    "While the matched sample estimate reduces the effect size, it also requires a number of choices to be made such as the distance threshold used or whether to match with or without replacement.\n",
    "Finally, matching is only as good as the covariates available. Though LDA topics are a sensible choice one could imagine other variables such as time of day, gender of the person posting, post length and more. Such covariates were excluded for this tutorial for simplicity.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
